{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gongzheng/anaconda3/envs/deepseek/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "import warnings\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:08<00:00,  1.19s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"/data/gongzheng/llm/deepseek-moe-16b-chat\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, trust_remote_code=True).to(\"cuda:4\")\n",
    "model.generation_config = GenerationConfig.from_pretrained(model_name)\n",
    "model.generation_config.pad_token_id = model.generation_config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = 'what is the name and nation of the singer who have a song having \"Hey\" in its name? | singer : singer.country , singer.song_name , singer.name , singer.singer_id , singer.age | stadium : stadium.location , stadium.name , stadium.capacity , stadium.highest , stadium.lowest | singer_in_concert : singer_in_concert.concert_id , singer_in_concert.singer_id | concert : concert.theme , concert.year , concert.concert_id , concert.concert_name , concert.stadium_id | concert.stadium_id = stadium.stadium_id | singer_in_concert.singer_id = singer.singer_id | singer_in_concert.concert_id = concert.concert_id'\n",
    "question, schemas = input_sequence.split('|', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": f\"There are a database has several tables: {schemas}, can you give me the SQL about {question}\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'There are a database has several tables:  singer : singer.country , singer.song_name , singer.name , singer.singer_id , singer.age | stadium : stadium.location , stadium.name , stadium.capacity , stadium.highest , stadium.lowest | singer_in_concert : singer_in_concert.concert_id , singer_in_concert.singer_id | concert : concert.theme , concert.year , concert.concert_id , concert.concert_name , concert.stadium_id | concert.stadium_id = stadium.stadium_id | singer_in_concert.singer_id = singer.singer_id | singer_in_concert.concert_id = concert.concert_id, can you give me the SQL about what is the name and nation of the singer who have a song having \"Hey\" in its name? '}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "No chat template is defined for this tokenizer - using the default template for the LlamaTokenizerFast class. If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n```sql\\nSELECT singer.name, singer.country\\nFROM singer\\nJOIN singer_in_concert ON singer.singer_id = singer_in_concert.singer_id\\nJOIN concert ON singer_in_concert.concert_id = concert.concert_id\\nJOIN stadium ON concert.stadium_id = stadium.stadium_id\\nWHERE singer_in_concert.concert_id IN (\\n    SELECT concert_id\\n    FROM singer_in_concert\\n    WHERE song_name LIKE \\'%Hey%\\'\\n)\\nAND singer.singer_id IN (\\n    SELECT singer_id\\n    FROM singer_in_concert\\n    WHERE song_name LIKE \\'%Hey%\\'\\n);\\n```\\n\\nThis SQL query will return the name and nation of the singer who have a song having \"Hey\" in its name. It first joins the tables together to get the necessary information, then it uses a subquery to find the concert_id of the concerts that have a song with \"Hey\" in its name. Finally, it uses these concert_id to find the singer who performed in these concerts.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# messages = [{\"role\": \"user\", \"content\": f\"There are a database has several tables: {schema}, can you give me the SQL about {question}\"}]\n",
    "input_tensor = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\")\n",
    "outputs = model.generate(input_tensor.to(model.device), max_new_tokens=250)\n",
    "\n",
    "result = tokenizer.decode(outputs[0][input_tensor.shape[1]:], skip_special_tokens=True)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" SELECT singer.name, singer.country FROM singer JOIN singer_in_concert ON singer.singer_id = singer_in_concert.singer_id JOIN concert ON singer_in_concert.concert_id = concert.concert_id JOIN stadium ON concert.stadium_id = stadium.stadium_id WHERE singer_in_concert.concert_id IN (     SELECT concert_id     FROM singer_in_concert     WHERE song_name LIKE '%Hey%' ) AND singer.singer_id IN (     SELECT singer_id     FROM singer_in_concert     WHERE song_name LIKE '%Hey%' )  \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"```sql(.*)```\", result, re.DOTALL)[0].replace('\\n', ' ').replace(';', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/preprocessed_data/resdsql_dev_natsql.json\") as f:\n",
    "    eval_data = json.load(f)\n",
    "\n",
    "input_sequences = [x['input_sequence'] for x in eval_data]\n",
    "output_sqls = [x['output_sequence'].split('|')[1] for x in eval_data]\n",
    "\n",
    "input_sequences[0]\n",
    "input_sequences[0].split('|', 1)\n",
    "question, schema = input_sequences[0].split('|', 1)\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "fail_question = []\n",
    "fail_sql = []\n",
    "\n",
    "with open(\"data/output/deepseek-moe-16b-chat.json\", \"a+\") as f:\n",
    "    for input_seq, output_sql in tqdm(zip(input_sequences[:5], output_sqls[:5])):\n",
    "        try:\n",
    "            question, schema = input_seq.split('|', 1)\n",
    "            messages = [{\"role\": \"user\", \"content\": f\"There are a database has several tables: {schema}, can you give me the SQL about {question}\"}]\n",
    "            input_tensor = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\")\n",
    "            outputs = model.generate(input_tensor.to(model.device), max_new_tokens=200)\n",
    "            result = tokenizer.decode(outputs[0][input_tensor.shape[1]:], skip_special_tokens=True)\n",
    "            result_sql = re.findall(r\"```sql(.*)```\", result, re.DOTALL)[0].replace('\\n', ' ').replace(';', ' ')\n",
    "            f.write(result_sql + '\\n')\n",
    "            f.write(output_sql + '\\n')\n",
    "        except Exception as e:\n",
    "            fail_question.append(input_seq)\n",
    "            fail_sql.append(output_sql)\n",
    "            \n",
    "with open(\"data/output/deepseek-moe-16b-chat-fail.json\", \"a+\") as f:\n",
    "    for input_seq, output_sql in tqdm(zip(fail_question, fail_sql)):\n",
    "        f.write(input_seq + '\\n')\n",
    "        f.write(output_sql + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepseek",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
